{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a new BoM from 3dx files\n",
    "\n",
    "This is reading in extracts produced by 3dx, adding the function group and system/subsystem, and doing the roll up quantity calcs in the absence of 3DX doing that.\n",
    "\n",
    "The script does the following functions that is missing from 3DX currently:\n",
    "\n",
    "* Populate Function Group/System/Sub System – not fully populated in 3DX for all parts and this is needed downstream for reporting\n",
    "* Add Percentage Missing calculations for all attributes/columns for EDAG reporting\n",
    "* Create a matching key for Smartsheets processing\n",
    "* Add last Export Date to top of export and as a column \n",
    "* Add BOM COUNT validation column\n",
    "* Add Parent Part column – not maintained in 3DX and requested by downstream systems\n",
    "* Validates all mandatory attributes are included before processing any further\n",
    "* If Quantity doesn’t exist (comes only from XEN tool) then group parts and create Quantity column (removes the reliance on XEN license)\n",
    "* Clear zero values, ‘not set’ and blank spaces from 3DX extract – zero does not mean the attribute is populated and needs to be removed to show it requires completion\n",
    "* Add Part Number validation and report where it doesn’t adhere to part numbering standard – creates validation columns at the far right of the export\n",
    "* Force the order of selected key attributes to the left as not always maintained in 3DX extract files\n",
    "* Derive the export folder to send file to and name file for Data Shuttle to pick up – top level ‘Title’ (ie T48e-01-Z00001 = VP 5 door master product - T48e-01-Z00001’\n",
    "* Identify where a part is a lowest level child part and add a ‘has_child’ column to support Smartsheet Mass calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import io\n",
    "import time\n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import xlwings as xw\n",
    "import glob\n",
    "import configparser\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "import platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(download_dir):\n",
    "    # find any changed files changed in past 2hrs in the downloads directory\n",
    "    dirpath = download_dir\n",
    "    past = time.time() - 2*60*60 # 2 hours\n",
    "    files = []\n",
    "    for p, ds, fs in os.walk(dirpath):\n",
    "        for fn in fs:\n",
    "            # was using this to filter what filenames to find\n",
    "            if 'ENO' in fn:            \n",
    "                filepath = os.path.join(p, fn)\n",
    "                if os.path.getmtime(filepath) >= past:\n",
    "                    files.append(filepath)\n",
    "\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_file(file):\n",
    "    # get 3dx extract\n",
    "    print (\"opening {} at: {}\".format(file, time.strftime(\"%H:%M:%S\", time.localtime())))\n",
    "    with open(file, \"rb\") as f:\n",
    "        try:\n",
    "\n",
    "            if 'csv' in file:\n",
    "                BOM = pd.DataFrame()\n",
    "                BOM = pd.read_csv(f, low_memory=False) \n",
    "                # skip first n rows that are header information out of 3DX\n",
    "                if 'Level' not in BOM.columns:\n",
    "                    print (\"didn't get the column headers so finding them myself\")            \n",
    "                    n = BOM[BOM.iloc[:, 0] == 'Level'].index.values[0]\n",
    "                    # create the column headers\n",
    "                    BOM.columns = BOM.iloc[n]\n",
    "                    # drop the top rows above the header row we found\n",
    "                    BOM = BOM[n+1:]\n",
    "\n",
    "            if 'xls' in file:\n",
    "                # BOM = pd.read_csv(f, low_memory=False, skiprows=8) \n",
    "                BOM = pd.read_excel(f)             \n",
    "            # sheetnames = [sheet for sheet in f.sheet_names]\n",
    "        except Exception as e:\n",
    "            print (\"{}\".format(e))\n",
    "\n",
    "    return BOM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_function_group(df):\n",
    "    # Add Function and Sub Group if it doesn't already exist\n",
    "\n",
    "    # - Level 0 = Model Variant   \n",
    "    # - Level 1 = Function Group Area   \n",
    "    # - Level 2 = System   \n",
    "    # - Level 3 = Sub Systems\n",
    "    # - level 4 = AMs/SAs??\n",
    "\n",
    "    # Find each one and forward fill to the next occurrence\n",
    "    # function group - level 1\n",
    "    df['Function Group'] = np.where(df['Level'].isin([0,1]), df['Description'], None)\n",
    "    df['Function Group'] = df['Function Group'].ffill()\n",
    "\n",
    "    # System - level 2\n",
    "    df['System'] = np.where(df['Level'] == 2, df['Description'], None)\n",
    "    df['System'] = np.where(df['Level'] >= 2, df['System'].ffill(), None)\n",
    "\n",
    "    # SUB_System = level 3\n",
    "    df['Sub System'] = np.where(df['Level'] == 3, df['Description'], None)\n",
    "    df['Sub System'] = np.where(df['Level'] >= 3, df['Sub System'].ffill(), df['Sub System'])\n",
    "\n",
    "    # Level 4 - for grouping mass and cost roll up for Carlos/smartsheets\n",
    "    df['Level_4_Parent'] = np.where(df['Level'] == 4, df['Title'], None)\n",
    "    df['Level_4_Parent'] = np.where(df['Level'] >= 4, df['Level_4_Parent'].ffill(), df['Level_4_Parent'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df):\n",
    "    # keep python index as 'orig_sort' - useful for knowing you've maintained the BoM structure/order\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index':'orig_sort'}, inplace=True)\n",
    "\n",
    "    # sometimes column came through as Title (Instance) \n",
    "    try:\n",
    "        df.rename(columns={'Title (Instance)':'Instance Title'}, inplace=True)\n",
    "    except ValueError:\n",
    "        print (\"didn't find Title (Instance) to rename\")\n",
    "\n",
    "    # 3dx calls Quantity Occurrences\n",
    "    try:\n",
    "        df.rename(columns={'Occurrences':'Quantity'}, inplace=True)\n",
    "    except ValueError:\n",
    "        print (\"didn't find Occurrences to rename\")\n",
    "\n",
    "    # replace any Mass (kg) columns with Mass\n",
    "    df.columns = df.columns.str.replace('Mass (kg)', 'Mass')\n",
    "\n",
    "\n",
    "    return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bi_key(df):\n",
    "    # for use in power_bi reporting\n",
    "    # replace NaN with ''\n",
    "    df['bi_combined_key'] = df['Function Group'] + df['System'].astype(str) + df['Sub System'].astype(str)\n",
    "    \n",
    "    return df['bi_combined_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_matching_key(df):\n",
    "    # for us in smartsheets\n",
    "    df['Matching Key'] = np.where(df['Parent Part'].isna(), df['Title'].astype(str), df[\"Title\"].astype(str) + df[\"Parent Part\"].astype(str))\n",
    "    # force matching key to always be upper case whilst there is inconsistency within 3dx.  Otherwise, doesn't match dup parts\n",
    "    df['Matching Key'] = df['Matching Key'].str.upper()\n",
    "    # build cumulative count for each part\n",
    "    df['cumcount'] = df.groupby('Matching Key').cumcount()+1\n",
    "    # not interested in the first occurrence of a part - blank out the first cumcount of each group\n",
    "    df['cumcount'] = np.where(df['cumcount']==1, '', df['cumcount'])\n",
    "    df['Matching Key'] = df['Matching Key'].astype(str) + df['cumcount'].astype(str)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smartsheet_cols(df, extract_date):\n",
    "    # need to correct the percent missing for matching key column\n",
    "    df.loc['percent_missing','Matching Key'] = 0\n",
    "    df['Last Export Date'] = extract_date\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mandatory_attributes(bom_cols):\n",
    "    # read in mandatory fields from file in same directory\n",
    "    with open('mandatory_attributes.ini', 'r') as f:\n",
    "        lst = f.readlines()\n",
    "\n",
    "    mand_cols = [line.rstrip() for line in lst]\n",
    "\n",
    "    missing_cols = list(set(mand_cols) - set(bom_cols))\n",
    "\n",
    "    if len(missing_cols) > 0:\n",
    "        print (\"missing mandatory attributes: {}\".format(missing_cols))\n",
    "        sys.exit()\n",
    "\n",
    "    return mand_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_columns(df):\n",
    "    # this specifies the order of the left most cols.  Columns not mentioned below then appear alphabetically afterwards\n",
    "    cols_to_order = ['BOM COUNT',\n",
    "        'Matching Key',\n",
    "        'Last Export Date',\n",
    "        'orig_sort',\n",
    "        'Function Group',\n",
    "        'System',\n",
    "        'Sub System',\n",
    "        'Level_4_Parent',\n",
    "        'Level',\n",
    "        'Title',\n",
    "        'Parent Part',\n",
    "        'Revision',\n",
    "        'Description',\n",
    "        'Name',\n",
    "        'Quantity',\n",
    "        'Source Code',\n",
    "        'UOM',\n",
    "        'Provide',\n",
    "        'Actual Mass',\n",
    "        'CAD Mass',\n",
    "        'CAD Material',\n",
    "        'Programme Maturity']\n",
    "        # 'Subtype']\n",
    "    \n",
    "    # # write out mandatory attributes to local file.  Not reading in from here as there is always some code change required anyway!\n",
    "    # with open('mandatory_attributes.ini', 'w') as f:\n",
    "    #     for col in cols_to_order:\n",
    "    #         # ignore the internal cols I create\n",
    "    #         if col not in (['Matching Key','Last Export Date','orig_sort','Parent Part']):\n",
    "    #             f.write('{}\\n'.format(col))\n",
    "\n",
    "    try:\n",
    "        ordered_cols = cols_to_order + (df.columns.sort_values().drop(cols_to_order).tolist())\n",
    "        df = df[ordered_cols]\n",
    "    except KeyError as e:\n",
    "        raise Exception (\"Missing an expected column in the extract: {}\".format(e))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sa_index(df):\n",
    "    # fill level 3s with orig_sort\n",
    "    # ffill everything with the level 3 orig_sort\n",
    "    # fill level 4s with the level 3 orig_sort + its own orig_sort\n",
    "    # fill < level 3 with own orig_sort\n",
    "    # NaN > level 4 and refill with the sa_index from level 4 above\n",
    "    df['SA_Index'] = np.where(df['Level'] == 3, df['orig_sort'].astype(str), np.nan)\n",
    "    df['SA_Index'] = df['SA_Index'].ffill()\n",
    "    df['SA_Index'] = np.where(df['Level'] == 4, df['SA_Index'] + '_' + df['orig_sort'].astype(str), df['SA_Index'])\n",
    "    # forward fill so that > Level 5 get the same index\n",
    "    df['SA_Index'] = np.where(df['Level'] < 3, df['orig_sort'].astype(str), df['SA_Index'])\n",
    "    df['SA_Index'] = np.where(df['Level'] > 4, np.nan, df['SA_Index'])\n",
    "    df['SA_Index'] = df['SA_Index'].ffill()\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sa_index2(df):\n",
    "    # this was attempting to rely on 3dx labelling of an Assembly - didn't work all of the time\n",
    "    df['SA_Index'] = np.where(df['Assembly'], df['orig_sort'].astype(str), np.nan)\n",
    "    df['SA_Index'] = df['SA_Index'].ffill()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_quantities(df):\n",
    "\n",
    "    # if the extract hasn't come with quantity column then we need to calculate our own grouping of like parts together\n",
    "    # this is only being done for level 4 and greater - level 4 is assumed to be assembly level\n",
    "    # there is a potential problem with this if the extract is not produced for the top level part of a structure\n",
    "    \n",
    "    # groupby:\n",
    "    # SA_Index - created earlier, this will group the parts within an assembly (level 4 and greater) \n",
    "    # Title - this is the part number\n",
    "    # Parent Part - created earlier, this will group only parts at the same level with the same parent\n",
    "    # Level - this is probably not required if we are using parent part, but ensures we group at the same level\n",
    "\n",
    "    # groupby Title and sum (size).  Save as a new df called qty\n",
    "    qty = BOM_pp.groupby(['SA_Index','Title','Parent Part','Level'], dropna=False).size().reset_index(name='Quantity')\n",
    "    # qty = BOM_pp.groupby(['Title','Parent Part','Level'], dropna=False).size().reset_index(name='Quantity')\n",
    "\n",
    "    # merge qty with BOM on SA_Index to get all the other columns back\n",
    "    qty2 = pd.merge(qty, BOM_pp, on=['SA_Index','Title','Parent Part','Level'])\n",
    "    # qty2 = pd.merge(qty, BOM_pp, on=['Title','Parent Part','Level'])\n",
    "    # qty2 = pd.concat([qty, BOM_pp])\n",
    "\n",
    "    # need to drop dups using only a subset of cols, creating new_bom df\n",
    "    new_bom = qty2.drop_duplicates(subset=['SA_Index','Title','Parent Part', 'Level'])\n",
    "    # new_bom = qty2.drop_duplicates(subset=['Title','Parent Part', 'Level'])\n",
    "    # sort the new_nom df by the orig_sort field to make sure it's the order it came out of 3dx\n",
    "    new_bom = new_bom.sort_values(by='orig_sort')\n",
    "    \n",
    "    # don't think there are any names to rename?\n",
    "    new_bom.rename(columns={\n",
    "        'Title_y':'Title',\n",
    "        'Parent Part_x':'Parent Part',\n",
    "        'Quantity_x':'Quantity',\n",
    "        'Level_x':'Level'\n",
    "    }, inplace=True)    \n",
    "\n",
    "    return new_bom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parent_part(df):\n",
    "    # reset index before trying to update, otherwise multiple rows get updated\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    df['Parent Part'] = None\n",
    "\n",
    "    level = {}\n",
    "    previous_parent_part=0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        current_part_number = row['Title']\n",
    "        current_part_level = row['Level']\n",
    "\n",
    "        # write part number to dictionary under current part level\n",
    "        level[current_part_level] = current_part_number\n",
    "\n",
    "        # reset higher levels for each assembly\n",
    "        # remove entries from higher levels\n",
    "        keys = [k for k in level if k > current_part_level]\n",
    "        for x in keys:\n",
    "            del level[x]\n",
    "\n",
    "        if current_part_level > 0:\n",
    "            # get the max part level from the level dictionary that's less than current part level\n",
    "            previous_parent_level = max(k for k in level if k < current_part_level)\n",
    "\n",
    "            # update the parent part\n",
    "            # print (i, \"Parent part {} from previous level {}\".format(level[previous_parent_level], previous_parent_level))\n",
    "            df.at[i,'Parent Part'] = level[previous_parent_level]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gparent_part(df):\n",
    "    # reset index before trying to update, otherwise multiple rows get updated\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    df['Parent Part'] = None\n",
    "    df['Matching Key'] = None\n",
    "\n",
    "    level = {}\n",
    "    previous_part_level=0\n",
    "    gparent_part_level=0\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        current_part_number = row['Title']\n",
    "        current_part_level = row['Level']\n",
    "\n",
    "        # write part number to dictionary under current part level\n",
    "        level[current_part_level] = current_part_number\n",
    "\n",
    "        # reset higher levels for each assembly\n",
    "        # remove entries from higher levels\n",
    "        keys = [k for k in level if k > current_part_level]\n",
    "        for x in keys:\n",
    "            del level[x]\n",
    "\n",
    "        if current_part_level > 0:\n",
    "            # get the max part level from the level dictionary that's less than current part level\n",
    "            previous_part_level = max(k for k in level if k < current_part_level)\n",
    "\n",
    "            # update the parent part\n",
    "            # print (i, \"Parent part {} from previous level {}\".format(level[previous_parent_level], previous_parent_level))\n",
    "            df.at[i,'Parent Part'] = level[previous_part_level]\n",
    "        \n",
    "        # if previous_part_level > 0:\n",
    "            # get the max part level from the level dictionary that's less than previous parent level\n",
    "            # gparent_part_level = max(k for k in level if k < previous_part_level)\n",
    "            # gparent_part_level = ''.join((level.values()))\n",
    "\n",
    "\n",
    "            # update the parent part\n",
    "            # print (i, \"Parent part {} from previous level {}\".format(level[previous_parent_level], previous_parent_level))\n",
    "        df.at[i,'Matching Key'] = ''.join((level.values()))\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_xml(df):\n",
    "    BOM_xml = df\n",
    "    # get rid of spaces, slashes and chars xml can't handle\n",
    "    BOM_xml.columns = df.columns.str.replace(' ', '_')\n",
    "    BOM_xml.columns = df.columns.str.replace('/', '_')\n",
    "    BOM_xml.columns = df.columns.str.replace('&', '')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shuttle_folder(product):\n",
    "    # After update of BoM names\n",
    "    # •\tVP 5 door master product - T48e-01-Z00001 \n",
    "    # •\tVP 3 door master product - T48e-02-Z00001\n",
    "    # •\tXP 5 door master product – T48e-01-Z00005\n",
    "    # •\tVP 3 door master product - T48e-02-Z00005\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config_file = 'product_structures_config.ini'\n",
    "    config.read(config_file)\n",
    "\n",
    "    # read the Product_Structures section and look up the product\n",
    "    try:\n",
    "        ds_folder = config['Product_Structures'][product]\n",
    "    except KeyError:\n",
    "        print (\"No entry in file {}, section: Product_Structures, for key {}.  Using 'default'\".format(config_file, product))\n",
    "        ds_folder = 'default'\n",
    "\n",
    "    return ds_folder\n",
    "    \n",
    "\n",
    "    # if 'T48e-01-Z00001' in product:\n",
    "    #     return 'VP 5 door master product - T48e-01-Z00001'\n",
    "    # elif 'T48e-02-Z00001' in product:\n",
    "    #     return 'XP 3 door master product - T48e-02-Z00001'\n",
    "    # elif 'T48e-01-Z00005' in product:\n",
    "    #     return 'XP 5 door master product – T48e-01-Z00005'\n",
    "    # elif 'T48e-02-Z00005' in product:\n",
    "    #     return 'VP 3 door master product - T48e-02-Z00005'\n",
    "    # elif 'T48e-M1-Z00001' in product:\n",
    "    #     return 'Chassis Mule - T48e-M1-Z00001'\n",
    "    # elif 'T48e-01-Z00003' in product:\n",
    "    #     return 'Kinematics and compliance - T48e-01-Z00003'\n",
    "    # elif 'T53-Z00001' in product:\n",
    "    #     return 'T53 - Z00001 - BOM Export'\n",
    "    # elif 'T53-Z00002' in product:\n",
    "    #     return 'T53 - Z00002 - BOM Export'\n",
    "    # else:\n",
    "    #     return 'default'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def COG_split(df):\n",
    "    # split the COG field (where it is populated) into COG x, COG y, COG z \n",
    "    # need to make sure COG is a string field - if is it completely empty, all nan will make it float\n",
    "    df.COG = df.COG.astype('object')\n",
    "\n",
    "    # then try to split into three columns\n",
    "    try:\n",
    "        df[['COG X', 'COG Y', 'COG Z']] = df['COG'].str.split(',', expand=True)\n",
    "    except ValueError:\n",
    "        # will fail if there is nothing to split on, so create 3 cols with NaN\n",
    "        df[['COG X', 'COG Y', 'COG Z']] = np.NaN\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_zero_values(df):\n",
    "    value_cols = df.select_dtypes(exclude=[object]).columns\n",
    "    value_cols = value_cols.drop(['Level','orig_sort'])\n",
    "\n",
    "    # convert 0.0 to na\n",
    "    df[value_cols] = np.where(df[value_cols] == 0, np.NaN, df[value_cols])\n",
    "\n",
    "    # for COG, convert 0,0,0 to na\n",
    "    df['COG'] = np.where(df['COG'] == '0,0,0', np.NaN, df['COG'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_not_set_values(df):\n",
    "    df = df.replace('Not Set', np.NaN)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_na_values(df):\n",
    "    # populate Provide with 'N/A' for source code SYS and ENG\n",
    "    df['Provide'] = np.where(df['Source Code'].isin(['SYS','ENG']), 'N/A', df['Provide'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_missing(df):\n",
    "    df.loc['percent_missing'] = None\n",
    "    df.loc['percent_missing'] = df.isnull().sum(axis=0) * 100 / len(df)\n",
    "    # df.loc['percent_missing'] = df.loc['percent_missing'].astype(int)\n",
    "    df.loc['percent_missing','orig_sort'] = 'percent_missing'\n",
    "    new_df = pd.concat([df.iloc[-1:].copy(), df.iloc[:-1].copy()])\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_part_no(df):\n",
    "\n",
    "    # ? means the preceding bracketed group is optional (optional s,S and trailing X)\n",
    "    # pattern = r'([A-Z]\\d{2}([s,S])?-[A-Z]\\d{4}(X)?)'\n",
    "    # pattern = r'[A-Z]\\d{2}[e]-[A-Z]\\d{5}+X?'\n",
    "    # pattern = r'([A-Z]\\d{2}[e])-([A-Z])(\\d{5})(X)'\n",
    "    pattern = r'([A-Z]\\d{2}[e])-(\\w[A-Za-z0-9]*)?-?([A-Z])(\\d{5})(X)?'\n",
    "    df[['extr_project','extr_invalid_code','extr_function','extr_pn','extr_maturity']] = df['Title'].str.extract(pattern, expand=True)\n",
    "\n",
    "    df['part_number_length'] = df['Title'].str.len()\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_blanks(df):\n",
    "    # replace an empty string and records with only spaces\n",
    "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(x):\n",
    "    try:\n",
    "        return dt.datetime.strptime(x, '%Y-%m-%d')\n",
    "    except:\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_excel(df, outfile):\n",
    "    from openpyxl import load_workbook\n",
    "\n",
    "    # update if exists\n",
    "    try:\n",
    "        wb = load_workbook(outfile)\n",
    "        with pd.ExcelWriter(outfile, engine='openpyxl') as writer:\n",
    "            writer.workbook = wb\n",
    "            df.to_excel(writer, index=False)\n",
    "            print (\"BOM written to existing file {}\".format(outfile))\n",
    "    except (FileNotFoundError):\n",
    "        df.to_excel(outfile, index=False)\n",
    "        print (\"BOM written to new file {}\".format(outfile))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XCADEmbeddedCmp means it is an Embedded Component, which means its behaves like an Assembly (so it has child parts), but it usually only exists in the context of its parent. So for your purposes, it should be flagged as an Assembly. \n",
    "\n",
    "I think KPKV5EquivalentComputed is just another element of the inertia measure function which is on the part template, so it appears whether or not its had the mass calculated. For the two parts that don't have KPKV5EquivalentComputed, it might mean they were created from a different template. \n",
    "\n",
    "‘XCAD Extension’ and ‘XCADExtension’ are the same, I think its just displaying differently on its own than when its concatenated into a string with other values. If they don't have 3DPart then they are Assemblies. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_subtype(df):\n",
    "    \n",
    "    df.Subtype.replace({'XCAD Extension':'Assembly',\n",
    "                        'XCADExtension':'Assembly',\n",
    "                        'XCADEmbeddedCmp':'Assembly',\n",
    "                            '3DPart':'Part3D',\n",
    "                            'XCADExposedPLMParameterSet':'COG and Mass Calculated'}, \n",
    "                            regex=True,\n",
    "                            inplace=True)\n",
    "                \n",
    "    df.Subtype = df.Subtype.str.split(',')\n",
    "    df.Subtype = df.Subtype.fillna(\"\").apply(list)\n",
    "    # dynamically create columns\n",
    "    for i in sorted(set(sum(df.Subtype.tolist(),[]))):\n",
    "        # Create a new column \n",
    "        df[i] = df.Subtype.apply(lambda x: 1 if i in x else 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_child(df):\n",
    "    df['has_child'] = np.where(df.Level>=df.Level.shift(-1), 0, 1)\n",
    "    # set last row to has_child = 0 because there isn't anything below it\n",
    "    df.loc[df.index[-1],'has_child'] = 0\n",
    "\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening C:\\Users\\mark_\\Downloads\\ENOSCEN_APMay 30 2024 09 07 53.csv at: 11:00:41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mark_\\AppData\\Local\\Temp\\ipykernel_20432\\23892361.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.02693965517241379' has dtype incompatible with datetime64[us], please explicitly cast to a compatible dtype first.\n",
      "  df.loc['percent_missing'] = df.isnull().sum(axis=0) * 100 / len(df)\n",
      "C:\\Users\\mark_\\AppData\\Local\\Temp\\ipykernel_20432\\23892361.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'percent_missing' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc['percent_missing','orig_sort'] = 'percent_missing'\n",
      "C:\\Users\\mark_\\AppData\\Local\\Temp\\ipykernel_20432\\23892361.py:3: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.02693965517241379' has dtype incompatible with datetime64[us], please explicitly cast to a compatible dtype first.\n",
      "  df.loc['percent_missing'] = df.isnull().sum(axis=0) * 100 / len(df)\n",
      "C:\\Users\\mark_\\AppData\\Local\\Temp\\ipykernel_20432\\23892361.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'percent_missing' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc['percent_missing','orig_sort'] = 'percent_missing'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOM written to existing file C:\\Users\\mark_\\Downloads\\T48E\\Updated_T48E-01-Z00005_2024-05-30.xlsx\n",
      "BOM written to existing file C:\\Users\\mark_\\Downloads\\Data Shuttle\\XP 5 door master product - T48e-01-Z00005\\Updated_T48E-01-Z00005_2024-05-30.xlsx\n",
      "file written to C:\\Users\\mark_\\Downloads\\Data Shuttle\\XP 5 door master product - T48e-01-Z00005\\Updated_T48E-01-Z00005_2024-05-30.xlsx\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    if 'macOS' in platform.platform():\n",
    "        # set some defaults for testing on mac\n",
    "        download_dir = Path('/Users/mark/Downloads')\n",
    "        user_dir = download_dir\n",
    "        sharepoint_dir = download_dir\n",
    "\n",
    "    elif os.getlogin() == 'mark_':\n",
    "        # my test windows machine\n",
    "        download_dir = Path('C:/Users/mark_/Downloads')\n",
    "        user_dir = download_dir\n",
    "        sharepoint_dir = download_dir        \n",
    "\n",
    "    else:\n",
    "        # personal one drive\n",
    "        user_dir = 'C:/Users/USERNAME'\n",
    "\n",
    "        # replace USERNAME with current logged on user\n",
    "        user_dir = user_dir.replace('USERNAME', os.getlogin())\n",
    "\n",
    "        # read in config file\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('user_directory.ini')\n",
    "\n",
    "        # read in gm_dir and gm_docs from config file\n",
    "        gm_dir = Path(config[os.getlogin().lower()]['gm_dir'])\n",
    "        gm_docs = Path(config[os.getlogin().lower()]['gmt'])\n",
    "        # this may find more than one sharepoint directory\n",
    "        # sharepoint_dir = user_dir + \"/\" + gm_dir + \"/\" + gm_docs\n",
    "        sharepoint_dir = Path(user_dir / gm_dir / gm_docs)\n",
    "\n",
    "        # download_dir = os.path.join(sharepoint_dir, 'Data Shuttle', 'downloads')\n",
    "        download_dir = Path(sharepoint_dir / 'Data Shuttle' / 'downloads')\n",
    "\n",
    "    files = find_files(download_dir)\n",
    "\n",
    "    if len(files) == 0:\n",
    "        print (\"No files found in {}\".format(download_dir))\n",
    "       \n",
    "\n",
    "    else:\n",
    "        dict_df = {}\n",
    "\n",
    "        # loop in case more than 1 file\n",
    "        for file in files:\n",
    "            BOM = pd.DataFrame()\n",
    "            BOM = open_file(file)\n",
    "            orig_bom = BOM.copy()\n",
    "            \n",
    "            time_format = \"%Y-%m-%d %H:%M\"\n",
    "            curr_time = time.strftime(time_format, time.localtime())\n",
    "\n",
    "            # check mandatory attributes are present\n",
    "            mandatory_cols = mandatory_attributes(BOM.columns)\n",
    "\n",
    "            # if 'Function Group' not in BOM.columns:\n",
    "            BOM = add_function_group(BOM)\n",
    "            BOM = rename_columns(BOM)\n",
    "\n",
    "            # read the title from first row as product to this file after\n",
    "            product = BOM['Title'].loc[0]\n",
    "\n",
    "            # populate COG x, y, z from COG field\n",
    "            # 04/04/2024 - Jannik/Carlos - don't need separate COG cols anymore\n",
    "            # BOM = COG_split(BOM)\n",
    "\n",
    "            # add an SA_Index for the add_quantities stage\n",
    "            BOM_sa = create_sa_index(BOM)\n",
    "\n",
    "            BOM_pp = create_parent_part(BOM_sa)\n",
    "            #  don't want full MK after all!\n",
    "            # BOM_pp = create_gparent_part(BOM_sa)\n",
    "\n",
    "            # if we've not been given quantity we need to do the roll-up ourselves\n",
    "            if 'Quantity' not in BOM.columns:\n",
    "                # this creates the quantity column\n",
    "                BOM_pp = add_quantities(BOM_pp)\n",
    "\n",
    "            # don't include 'Part Number' from 3dx - it's not the real part number and confuses Carlos' process\n",
    "            try:\n",
    "                BOM_pp.drop('Part Number', axis=1, inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "            # don't keep SA_Index in output as not needed.            \n",
    "            try:\n",
    "                BOM_pp.drop('SA_Index', axis=1, inplace=True)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            BOM_pp = validate_part_no(BOM_pp)\n",
    "            \n",
    "            # BOM_ordered['Effectivity'] = BOM_ordered['Effectivity'].apply(convert_date)\n",
    "\n",
    "            dict_df[product] = BOM_pp\n",
    "\n",
    "            # replace only spaces in cells with NaN\n",
    "            BOM_pp = clear_blanks(BOM_pp)\n",
    "            # replace zero values with NaN\n",
    "            BOM_pp = clear_zero_values(BOM_pp)\n",
    "            # replace 'Not Set' values with NaN\n",
    "            BOM_pp = clear_not_set_values(BOM_pp)\n",
    "            # populate SYS and ENG source codes with 'N/A'\n",
    "            BOM_pp = set_na_values(BOM_pp)\n",
    "\n",
    "            # BOM_pp = split_subtype(BOM_pp)\n",
    "\n",
    "            # write out the updated filename with timestamp to the correct dir\n",
    "            project = product.split('-')[0]\n",
    "            output_file = 'Updated_{}_{}.xlsx'.format(product, curr_time.split()[0])\n",
    "            output_path = os.path.join(sharepoint_dir, project, output_file)\n",
    "            # automatically create the parent directories if don't exist\n",
    "            Path(output_path).parent.mkdir(parents=True, exist_ok=True)            \n",
    "            # print (\"file written to {}\".format(output_path))\n",
    "\n",
    "            # drop the filename timestamp for power bi \n",
    "            power_bi_file = 'Updated_{}.xlsx'.format(product)\n",
    "            # write to data shuttle directory for Carlos to pick up            \n",
    "            data_shuttle_file = 'Updated_{}_{}.xlsx'.format(product, curr_time.split()[0])\n",
    "            ds_folder = data_shuttle_folder(product)\n",
    "            data_shuttle_path = os.path.join(sharepoint_dir, 'Data Shuttle', ds_folder, data_shuttle_file)\n",
    "            # write out without timestamp for power bi\n",
    "            power_bi_path = os.path.join(sharepoint_dir, 'Data Shuttle', ds_folder, power_bi_file)\n",
    "            # automatically create the parent directories if don't exist\n",
    "            Path(data_shuttle_path).parent.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "            BOM_pp = add_matching_key(BOM_pp)\n",
    "\n",
    "            # get st_birthtime instead of creation time (deprecated) of 3dx file \n",
    "            extract_date = datetime.datetime.fromtimestamp(Path(file).stat().st_birthtime)\n",
    "            BOM_pp = add_smartsheet_cols(BOM_pp, extract_date)            \n",
    "            # format Last Export Date as datetime, with dayfirst\n",
    "            BOM_pp['Last Export Date'] = pd.to_datetime(BOM_pp['Last Export Date'], dayfirst=True)\n",
    "            # sort by orig_sort before writing out\n",
    "            BOM_pp = BOM_pp.sort_values(by='orig_sort')\n",
    "\n",
    "            BOM_pp = has_child(BOM_pp)\n",
    "\n",
    "            # drop packaging function group from the extract we send to data shuttle for processing\n",
    "            BOM_without_packaging = BOM_pp[~BOM_pp['Function Group'].str.contains('PACKAGING', na=False)]\n",
    "\n",
    "            # calculate percent missing after dropping packaging\n",
    "            BOM_without_packaging = percent_missing(BOM_without_packaging)\n",
    "            BOM_pp = percent_missing(BOM_pp)\n",
    "            BOM_without_packaging.loc['percent_missing','BOM COUNT'] = BOM_without_packaging.shape[0]\n",
    "            BOM_pp.loc['percent_missing','BOM COUNT'] = BOM_pp.shape[0]\n",
    "\n",
    "            # order the cols\n",
    "            BOM_ordered_without_packaging = order_columns(BOM_without_packaging)\n",
    "            BOM_ordered = order_columns(BOM_pp)\n",
    "            # write out the full file\n",
    "            write_to_excel(BOM_ordered, output_path)\n",
    "            # write out without packaging to data shuttle\n",
    "            write_to_excel(BOM_ordered_without_packaging, data_shuttle_path)\n",
    "            print (\"file written to {}\".format(data_shuttle_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CAD_Material_validation(df):\n",
    "    df[1:][df['Title'].str.contains('TPP', na=False)].groupby(['Title','CAD Material']).size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mass_roll_up(df):\n",
    "    g = df[1:][df['has_child'] == 0].groupby(['Function Group','System','Sub System','Level_4_Parent'])['CAD Mass'].agg(['sum','mean','max'])\n",
    "    import xlwings as xw\n",
    "\n",
    "    wb = xw.Book()\n",
    "    ws = wb.sheets[0]\n",
    "\n",
    "    ws['a1'].options(pd.DataFrame, header=True, index=True).value=g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_bi = BOM_ordered_without_packaging[1:].copy()\n",
    "for col in ['UOM','Provide','Source Code']:\n",
    "    power_bi['Missing {}'.format(col)] = np.where(power_bi[col].isnull(), 1, 0)\n",
    "\n",
    "power_bi['bi_combined_key'] = add_bi_key(power_bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing UOM</th>\n",
       "      <th>Missing Provide</th>\n",
       "      <th>Missing Source Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Function Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XP</th>\n",
       "      <td>131</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHASSIS SYSTEMS</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELECTRICAL SYSTEMS-5 DOOR-XP</th>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERIOR &amp; HVAC SYSTEMS-5 DOOR-XP</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIFESTYLE PRODUCTS XP</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MASTER PRODUCT-5 DOOR-XP</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POWERTRAIN SYSTEMS</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Missing UOM  Missing Provide  \\\n",
       "Function Group                                                    \n",
       "BODY SYSTEMS-5 DOOR-XP                     131              113   \n",
       "CHASSIS SYSTEMS                             49               50   \n",
       "ELECTRICAL SYSTEMS-5 DOOR-XP                29               18   \n",
       "INTERIOR & HVAC SYSTEMS-5 DOOR-XP            0                4   \n",
       "LIFESTYLE PRODUCTS XP                       16               16   \n",
       "MASTER PRODUCT-5 DOOR-XP                     0                0   \n",
       "POWERTRAIN SYSTEMS                          29               29   \n",
       "\n",
       "                                   Missing Source Code  \n",
       "Function Group                                          \n",
       "BODY SYSTEMS-5 DOOR-XP                             113  \n",
       "CHASSIS SYSTEMS                                     49  \n",
       "ELECTRICAL SYSTEMS-5 DOOR-XP                        18  \n",
       "INTERIOR & HVAC SYSTEMS-5 DOOR-XP                    4  \n",
       "LIFESTYLE PRODUCTS XP                               16  \n",
       "MASTER PRODUCT-5 DOOR-XP                             0  \n",
       "POWERTRAIN SYSTEMS                                  29  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_UOM = BOM_without_packaging[BOM_without_packaging.UOM.isna()]\n",
    "no_sc = BOM_without_packaging[BOM_without_packaging['Source Code'].isna()]\n",
    "no_Provide = BOM_without_packaging[BOM_without_packaging['Provide'].isna()]\n",
    "pd.crosstab(no_UOM['Function Group'], no_UOM['Source Code'], margins=True, margins_name='Totals', dropna=False).iloc[:-1].reset_index()\n",
    "power_bi.groupby(['Function Group'])[['Missing UOM','Missing Provide','Missing Source Code']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "UOM = pd.crosstab(power_bi['Function Group'], power_bi['Missing UOM'], margins=True).iloc[:-1].reset_index()\n",
    "UOM_pct = pd.crosstab(power_bi['Function Group'], power_bi['Missing UOM'], margins=True, normalize='index')\n",
    "SC = pd.crosstab(power_bi['Function Group'], power_bi['Missing Source Code'], margins=True).iloc[:-1].reset_index()\n",
    "SC_pct = pd.crosstab(power_bi['Function Group'], power_bi['Missing Source Code'], margins=True, normalize='index').iloc[:-1].reset_index()\n",
    "Provide = pd.crosstab(power_bi['Function Group'], power_bi['Missing Provide'], margins=True).iloc[:-1].reset_index()\n",
    "Provide_pct = pd.crosstab(power_bi['Function Group'], power_bi['Missing Provide'], margins=True, normalize='index').iloc[:-1].reset_index()\n",
    "\n",
    "xtabs = power_bi.groupby(['Function Group', 'Missing Source Code', 'Missing Provide', 'Missing UOM']).size().unstack([1,2,3]).sort_index().fillna(0).astype(int)\n",
    "\n",
    "\n",
    "total = xtabs.stack().sum(1)\n",
    "\n",
    "total = total.to_frame().unstack()\n",
    "\n",
    "final = pd.concat([total, xtabs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mark_\\AppData\\Local\\Temp\\ipykernel_20432\\2738944723.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  part_val = BOM_ordered_without_packaging[1:][BOM_ordered_without_packaging['Level']>=4].filter(regex='Title|extr|length')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>extr_function</th>\n",
       "      <th>extr_invalid_code</th>\n",
       "      <th>extr_maturity</th>\n",
       "      <th>extr_pn</th>\n",
       "      <th>extr_project</th>\n",
       "      <th>part_number_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>T48e-MF03-A02810</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02810</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>T48e-A05080X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>05080</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>T48e-A03581X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03581</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3549</th>\n",
       "      <td>T48e-CO99-A03553</td>\n",
       "      <td>A</td>\n",
       "      <td>CO99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03553</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3493</th>\n",
       "      <td>T48e-A03577X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03577</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3471</th>\n",
       "      <td>T48e-A02809X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>02809</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>T48e-MF03-A02809</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02809</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3531</th>\n",
       "      <td>T48e-A05059X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>05059</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>T48e-A03559X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03559</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>T48e-A04891X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>04891</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>T48e-A04892X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>04892</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>T48e-A02774X_JOINING_ELE</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>02774</td>\n",
       "      <td>T48e</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>T48e-MF02-A04936</td>\n",
       "      <td>A</td>\n",
       "      <td>MF02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04936</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478</th>\n",
       "      <td>T48e-A02844X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>02844</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3526</th>\n",
       "      <td>T48e-A04959X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>04959</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3530</th>\n",
       "      <td>T48e-A05021X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>05021</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>T48e-A03031X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03031</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3561</th>\n",
       "      <td>T48e-MF03-A04547</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04547</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3550</th>\n",
       "      <td>T48e-CO99-A04547</td>\n",
       "      <td>A</td>\n",
       "      <td>CO99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04547</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>T48e-A03029X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03029</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>T48e-MF03-A02825</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02825</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>T48e-A03030X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03030</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3557</th>\n",
       "      <td>T48e-MF03-A02826</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02826</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>T48e-MF03-A03027</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03027</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>T48e-C099-A03027</td>\n",
       "      <td>A</td>\n",
       "      <td>C099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03027</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3453</th>\n",
       "      <td>T48e-A00248X CRASH CAN-FRT-RH</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00248</td>\n",
       "      <td>T48e</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>T48e-A00248X CRASH CAN-FRT-R2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00248</td>\n",
       "      <td>T48e</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>T48e-A00248X CRASH CAN-FRT-RH_HAZ2</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00248</td>\n",
       "      <td>T48e</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3454</th>\n",
       "      <td>T48e-A00248X CRASH CAN-FRT-RH_1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00248</td>\n",
       "      <td>T48e</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3455</th>\n",
       "      <td>T48e-A00248X CRASH CAN-FRT-RH_HAZ1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00248</td>\n",
       "      <td>T48e</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3457</th>\n",
       "      <td>T48e-A00248X CRASH CAN-FRT-RH_HAZ2_1</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00248</td>\n",
       "      <td>T48e</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>T48e-A00867X FRONT BUMPER BEAM</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>00867</td>\n",
       "      <td>T48e</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@SKIN</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03985</td>\n",
       "      <td>T48e</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3500</th>\n",
       "      <td>T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03985</td>\n",
       "      <td>T48e</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03985</td>\n",
       "      <td>T48e</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3502</th>\n",
       "      <td>T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03985</td>\n",
       "      <td>T48e</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3503</th>\n",
       "      <td>T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03985</td>\n",
       "      <td>T48e</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03985</td>\n",
       "      <td>T48e</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3460</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3466</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3467</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3461</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3462</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3465</th>\n",
       "      <td>T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>01475</td>\n",
       "      <td>T48e</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>T48e-MF03-A03629</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03629</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3560</th>\n",
       "      <td>T48e-MF03-A04543</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04543</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3552</th>\n",
       "      <td>T48e-CO99-A04741</td>\n",
       "      <td>A</td>\n",
       "      <td>CO99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04741</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3563</th>\n",
       "      <td>T48e-MF03-A04741</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04741</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3497</th>\n",
       "      <td>T48e-A03971X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03971</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3498</th>\n",
       "      <td>T48e-A03972X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>03972</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3528</th>\n",
       "      <td>T48e-A05017X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>05017</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>T48e-A05018X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>05018</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>T48e-CO99-A04583</td>\n",
       "      <td>A</td>\n",
       "      <td>CO99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04583</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3562</th>\n",
       "      <td>T48e-MF03-A04583</td>\n",
       "      <td>A</td>\n",
       "      <td>MF03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04583</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3484</th>\n",
       "      <td>T48e-A02937X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>02937</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3485</th>\n",
       "      <td>T48e-A02939X</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X</td>\n",
       "      <td>02939</td>\n",
       "      <td>T48e</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3547</th>\n",
       "      <td>T48e-C099-A02729</td>\n",
       "      <td>A</td>\n",
       "      <td>C099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02729</td>\n",
       "      <td>T48e</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title extr_function  \\\n",
       "3555                                   T48e-MF03-A02810             A   \n",
       "3534                                       T48e-A05080X             A   \n",
       "3494                                       T48e-A03581X             A   \n",
       "3549                                   T48e-CO99-A03553             A   \n",
       "3493                                       T48e-A03577X             A   \n",
       "3471                                       T48e-A02809X             A   \n",
       "3554                                   T48e-MF03-A02809             A   \n",
       "3531                                       T48e-A05059X             A   \n",
       "3492                                       T48e-A03559X             A   \n",
       "3516                                       T48e-A04891X             A   \n",
       "3517                                       T48e-A04892X             A   \n",
       "3469                           T48e-A02774X_JOINING_ELE             A   \n",
       "3553                                   T48e-MF02-A04936             A   \n",
       "3478                                       T48e-A02844X             A   \n",
       "3526                                       T48e-A04959X             A   \n",
       "3530                                       T48e-A05021X             A   \n",
       "3490                                       T48e-A03031X             A   \n",
       "3561                                   T48e-MF03-A04547             A   \n",
       "3550                                   T48e-CO99-A04547             A   \n",
       "3488                                       T48e-A03029X             A   \n",
       "3556                                   T48e-MF03-A02825             A   \n",
       "3489                                       T48e-A03030X             A   \n",
       "3557                                   T48e-MF03-A02826             A   \n",
       "3558                                   T48e-MF03-A03027             A   \n",
       "3548                                   T48e-C099-A03027             A   \n",
       "3453                      T48e-A00248X CRASH CAN-FRT-RH             A   \n",
       "3452                      T48e-A00248X CRASH CAN-FRT-R2             A   \n",
       "3456                 T48e-A00248X CRASH CAN-FRT-RH_HAZ2             A   \n",
       "3454                    T48e-A00248X CRASH CAN-FRT-RH_1             A   \n",
       "3455                 T48e-A00248X CRASH CAN-FRT-RH_HAZ1             A   \n",
       "3457               T48e-A00248X CRASH CAN-FRT-RH_HAZ2_1             A   \n",
       "3459                     T48e-A00867X FRONT BUMPER BEAM             A   \n",
       "3499  T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@SKIN             A   \n",
       "3500  T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...             A   \n",
       "3501  T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...             A   \n",
       "3502  T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...             A   \n",
       "3503  T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...             A   \n",
       "3504  T48e-A03985X 1.1 BRKT-MNTG-BUMPER BEAM-FRONT@S...             A   \n",
       "3460  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3466  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3467  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3461  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3462  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3463  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3464  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3465  T48e-A01475X_1.1_BRKT-MNTG-BUMPER_BEAM-FRONT_R...             A   \n",
       "3559                                   T48e-MF03-A03629             A   \n",
       "3560                                   T48e-MF03-A04543             A   \n",
       "3552                                   T48e-CO99-A04741             A   \n",
       "3563                                   T48e-MF03-A04741             A   \n",
       "3497                                       T48e-A03971X             A   \n",
       "3498                                       T48e-A03972X             A   \n",
       "3528                                       T48e-A05017X             A   \n",
       "3529                                       T48e-A05018X             A   \n",
       "3551                                   T48e-CO99-A04583             A   \n",
       "3562                                   T48e-MF03-A04583             A   \n",
       "3484                                       T48e-A02937X             A   \n",
       "3485                                       T48e-A02939X             A   \n",
       "3547                                   T48e-C099-A02729             A   \n",
       "\n",
       "     extr_invalid_code extr_maturity extr_pn extr_project  part_number_length  \n",
       "3555              MF03           NaN   02810         T48e                16.0  \n",
       "3534               NaN             X   05080         T48e                12.0  \n",
       "3494               NaN             X   03581         T48e                12.0  \n",
       "3549              CO99           NaN   03553         T48e                16.0  \n",
       "3493               NaN             X   03577         T48e                12.0  \n",
       "3471               NaN             X   02809         T48e                12.0  \n",
       "3554              MF03           NaN   02809         T48e                16.0  \n",
       "3531               NaN             X   05059         T48e                12.0  \n",
       "3492               NaN             X   03559         T48e                12.0  \n",
       "3516               NaN             X   04891         T48e                12.0  \n",
       "3517               NaN             X   04892         T48e                12.0  \n",
       "3469               NaN             X   02774         T48e                24.0  \n",
       "3553              MF02           NaN   04936         T48e                16.0  \n",
       "3478               NaN             X   02844         T48e                12.0  \n",
       "3526               NaN             X   04959         T48e                12.0  \n",
       "3530               NaN             X   05021         T48e                12.0  \n",
       "3490               NaN             X   03031         T48e                12.0  \n",
       "3561              MF03           NaN   04547         T48e                16.0  \n",
       "3550              CO99           NaN   04547         T48e                16.0  \n",
       "3488               NaN             X   03029         T48e                12.0  \n",
       "3556              MF03           NaN   02825         T48e                16.0  \n",
       "3489               NaN             X   03030         T48e                12.0  \n",
       "3557              MF03           NaN   02826         T48e                16.0  \n",
       "3558              MF03           NaN   03027         T48e                16.0  \n",
       "3548              C099           NaN   03027         T48e                16.0  \n",
       "3453               NaN             X   00248         T48e                29.0  \n",
       "3452               NaN             X   00248         T48e                29.0  \n",
       "3456               NaN             X   00248         T48e                34.0  \n",
       "3454               NaN             X   00248         T48e                31.0  \n",
       "3455               NaN             X   00248         T48e                34.0  \n",
       "3457               NaN             X   00248         T48e                36.0  \n",
       "3459               NaN             X   00867         T48e                30.0  \n",
       "3499               NaN             X   03985         T48e                49.0  \n",
       "3500               NaN             X   03985         T48e                51.0  \n",
       "3501               NaN             X   03985         T48e                54.0  \n",
       "3502               NaN             X   03985         T48e                56.0  \n",
       "3503               NaN             X   03985         T48e                54.0  \n",
       "3504               NaN             X   03985         T48e                56.0  \n",
       "3460               NaN             X   01475         T48e                61.0  \n",
       "3466               NaN             X   01475         T48e                63.0  \n",
       "3467               NaN             X   01475         T48e                63.0  \n",
       "3461               NaN             X   01475         T48e                64.0  \n",
       "3462               NaN             X   01475         T48e                64.0  \n",
       "3463               NaN             X   01475         T48e                64.0  \n",
       "3464               NaN             X   01475         T48e                64.0  \n",
       "3465               NaN             X   01475         T48e                64.0  \n",
       "3559              MF03           NaN   03629         T48e                16.0  \n",
       "3560              MF03           NaN   04543         T48e                16.0  \n",
       "3552              CO99           NaN   04741         T48e                16.0  \n",
       "3563              MF03           NaN   04741         T48e                16.0  \n",
       "3497               NaN             X   03971         T48e                12.0  \n",
       "3498               NaN             X   03972         T48e                12.0  \n",
       "3528               NaN             X   05017         T48e                12.0  \n",
       "3529               NaN             X   05018         T48e                12.0  \n",
       "3551              CO99           NaN   04583         T48e                16.0  \n",
       "3562              MF03           NaN   04583         T48e                16.0  \n",
       "3484               NaN             X   02937         T48e                12.0  \n",
       "3485               NaN             X   02939         T48e                12.0  \n",
       "3547              C099           NaN   02729         T48e                16.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_val = BOM_ordered_without_packaging[1:][BOM_ordered_without_packaging['Level']>=4].filter(regex='Title|extr|length')\n",
    "part_val.dropna(subset=['extr_invalid_code','extr_maturity'], how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_reports = {}\n",
    "fg_combined = {}\n",
    "\n",
    "for col in ['Source Code','Provide','UOM']:\n",
    "    fg_reports['{} Counts by FG'.format(col)] = pd.crosstab(power_bi['Function Group'], power_bi[col], margins=True, margins_name='Totals', dropna=False).iloc[:-1]\n",
    "    fg_reports['{} Counts by FG'.format(col)].rename(columns={np.nan:'Missing'}, inplace=True)\n",
    "    # fg_reports['{} %ages by FG'.format(col)] = pd.crosstab(power_bi['Function Group'], power_bi[col], margins=True, margins_name='Totals', dropna=False, normalize=True).iloc[:-1].round(4)*100\n",
    "    # fg_reports['{} %ages by FG'.format(col)].rename(columns={np.nan:'Missing'}, inplace=True)\n",
    "\n",
    "for col in ['Source Code','Provide','UOM']:\n",
    "    # fg_combined['Missing {} %ages by FG, System, Sub System'.format(col)] = pd.crosstab([power_bi['Function Group'],power_bi['System'], power_bi['Sub System'], power_bi['bi_combined_key']], power_bi[col].isna(), margins=True, margins_name='Totals', normalize='index').iloc[:-1].round(4)*100\n",
    "    # fg_combined['Missing {} %ages by FG, System, Sub System'.format(col)].rename(columns={False:'Populated', True:'Missing'}, inplace=True)\n",
    "    fg_combined['Missing {} count by FG, System, Sub System'.format(col)] = pd.crosstab([power_bi['Function Group'],power_bi['System'], power_bi['Sub System'], power_bi['bi_combined_key']], power_bi[col].isna(), margins=True, margins_name='Totals').iloc[:-1]\n",
    "    fg_combined['Missing {} count by FG, System, Sub System'.format(col)].rename(columns={False:'Populated', True:'Missing'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Source Code</th>\n",
       "      <th>Populated</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Totals</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Function Group</th>\n",
       "      <th>System</th>\n",
       "      <th>Sub System</th>\n",
       "      <th>bi_combined_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">BODY SYSTEMS-5 DOOR-XP</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">EXTERIOR SYSTEMS-5 DOOR-XP</th>\n",
       "      <th>ACCESSORIES-5 DOOR-XP</th>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-XPACCESSORIES-5 DOOR-XP</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUMPERS-5 DOOR-XP</th>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-XPBUMPERS-5 DOOR-XP</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GLAZING-5 DOOR-XP</th>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-XPGLAZING-5 DOOR-XP</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORNAMENTATION &amp; TRIM-5 DOOR-XP</th>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-XPORNAMENTATION &amp; TRIM-5 DOOR-XP</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCREEN WIPERS-5 DOOR-XP</th>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-XPSCREEN WIPERS-5 DOOR-XP</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">POWERTRAIN SYSTEMS</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">THERMAL SYSTEMS</th>\n",
       "      <th>COOLANT HOSES</th>\n",
       "      <th>POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLANT HOSES</th>\n",
       "      <td>106</td>\n",
       "      <td>12</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COOLING HARDWARE</th>\n",
       "      <th>POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLING HARDWARE</th>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REFRIGERANT PIPES</th>\n",
       "      <th>POWERTRAIN SYSTEMSTHERMAL SYSTEMSREFRIGERANT PIPES</th>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TRANSMISSION SYSTEMS</th>\n",
       "      <th>FINAL DRIVE</th>\n",
       "      <th>POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSFINAL DRIVE</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSMISSION</th>\n",
       "      <th>POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSTRANSMISSION</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Source Code                                                                                                                          Populated  \\\n",
       "Function Group         System                     Sub System                     bi_combined_key                                                 \n",
       "BODY SYSTEMS-5 DOOR-XP EXTERIOR SYSTEMS-5 DOOR-XP ACCESSORIES-5 DOOR-XP          BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...          9   \n",
       "                                                  BUMPERS-5 DOOR-XP              BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...          5   \n",
       "                                                  GLAZING-5 DOOR-XP              BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...         11   \n",
       "                                                  ORNAMENTATION & TRIM-5 DOOR-XP BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...         43   \n",
       "                                                  SCREEN WIPERS-5 DOOR-XP        BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...          5   \n",
       "...                                                                                                                                        ...   \n",
       "POWERTRAIN SYSTEMS     THERMAL SYSTEMS            COOLANT HOSES                  POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLANT HOSES            106   \n",
       "                                                  COOLING HARDWARE               POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLING HARDWARE          31   \n",
       "                                                  REFRIGERANT PIPES              POWERTRAIN SYSTEMSTHERMAL SYSTEMSREFRIGERANT PIPES        115   \n",
       "                       TRANSMISSION SYSTEMS       FINAL DRIVE                    POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSFINAL DRIVE           7   \n",
       "                                                  TRANSMISSION                   POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSTRANSMISSION          1   \n",
       "\n",
       "Source Code                                                                                                                          Missing  \\\n",
       "Function Group         System                     Sub System                     bi_combined_key                                               \n",
       "BODY SYSTEMS-5 DOOR-XP EXTERIOR SYSTEMS-5 DOOR-XP ACCESSORIES-5 DOOR-XP          BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...        0   \n",
       "                                                  BUMPERS-5 DOOR-XP              BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...        0   \n",
       "                                                  GLAZING-5 DOOR-XP              BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...        0   \n",
       "                                                  ORNAMENTATION & TRIM-5 DOOR-XP BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...        0   \n",
       "                                                  SCREEN WIPERS-5 DOOR-XP        BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...        6   \n",
       "...                                                                                                                                      ...   \n",
       "POWERTRAIN SYSTEMS     THERMAL SYSTEMS            COOLANT HOSES                  POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLANT HOSES           12   \n",
       "                                                  COOLING HARDWARE               POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLING HARDWARE        16   \n",
       "                                                  REFRIGERANT PIPES              POWERTRAIN SYSTEMSTHERMAL SYSTEMSREFRIGERANT PIPES        1   \n",
       "                       TRANSMISSION SYSTEMS       FINAL DRIVE                    POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSFINAL DRIVE         0   \n",
       "                                                  TRANSMISSION                   POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSTRANSMISSION        0   \n",
       "\n",
       "Source Code                                                                                                                          Totals  \n",
       "Function Group         System                     Sub System                     bi_combined_key                                             \n",
       "BODY SYSTEMS-5 DOOR-XP EXTERIOR SYSTEMS-5 DOOR-XP ACCESSORIES-5 DOOR-XP          BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...       9  \n",
       "                                                  BUMPERS-5 DOOR-XP              BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...       5  \n",
       "                                                  GLAZING-5 DOOR-XP              BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...      11  \n",
       "                                                  ORNAMENTATION & TRIM-5 DOOR-XP BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...      43  \n",
       "                                                  SCREEN WIPERS-5 DOOR-XP        BODY SYSTEMS-5 DOOR-XPEXTERIOR SYSTEMS-5 DOOR-X...      11  \n",
       "...                                                                                                                                     ...  \n",
       "POWERTRAIN SYSTEMS     THERMAL SYSTEMS            COOLANT HOSES                  POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLANT HOSES         118  \n",
       "                                                  COOLING HARDWARE               POWERTRAIN SYSTEMSTHERMAL SYSTEMSCOOLING HARDWARE       47  \n",
       "                                                  REFRIGERANT PIPES              POWERTRAIN SYSTEMSTHERMAL SYSTEMSREFRIGERANT PIPES     116  \n",
       "                       TRANSMISSION SYSTEMS       FINAL DRIVE                    POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSFINAL DRIVE        7  \n",
       "                                                  TRANSMISSION                   POWERTRAIN SYSTEMSTRANSMISSION SYSTEMSTRANSMISSION       1  \n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Source Code'\n",
    "fg_combined['Missing {} count by FG, System, Sub System'.format(col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing UOM</th>\n",
       "      <th>Missing Provide</th>\n",
       "      <th>Missing Source Code</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Function Group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BODY SYSTEMS-5 DOOR-XP</th>\n",
       "      <td>131</td>\n",
       "      <td>113</td>\n",
       "      <td>113</td>\n",
       "      <td>357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHASSIS SYSTEMS</th>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>49</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ELECTRICAL SYSTEMS-5 DOOR-XP</th>\n",
       "      <td>29</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERIOR &amp; HVAC SYSTEMS-5 DOOR-XP</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIFESTYLE PRODUCTS XP</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POWERTRAIN SYSTEMS</th>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Missing UOM  Missing Provide  \\\n",
       "Function Group                                                    \n",
       "BODY SYSTEMS-5 DOOR-XP                     131              113   \n",
       "CHASSIS SYSTEMS                             49               50   \n",
       "ELECTRICAL SYSTEMS-5 DOOR-XP                29               18   \n",
       "INTERIOR & HVAC SYSTEMS-5 DOOR-XP            0                4   \n",
       "LIFESTYLE PRODUCTS XP                       14               14   \n",
       "POWERTRAIN SYSTEMS                          29               29   \n",
       "\n",
       "                                   Missing Source Code  Total  \n",
       "Function Group                                                 \n",
       "BODY SYSTEMS-5 DOOR-XP                             113    357  \n",
       "CHASSIS SYSTEMS                                     49    148  \n",
       "ELECTRICAL SYSTEMS-5 DOOR-XP                        18     65  \n",
       "INTERIOR & HVAC SYSTEMS-5 DOOR-XP                    4      8  \n",
       "LIFESTYLE PRODUCTS XP                               14     42  \n",
       "POWERTRAIN SYSTEMS                                  29     87  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = power_bi[['Function Group','Missing UOM','Missing Provide','Missing Source Code']][power_bi['Level']>3].groupby(['Function Group']).sum()\n",
    "g['Total'] = g.sum(axis=1)\n",
    "g\n",
    "# pd.crosstab([power_bi['Missing UOM'], power_bi['Missing Source Code'], power_bi['Missing Provide']], power_bi['Function Group'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_heatmap(df, figsize):\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "       \n",
    "    hmap = plt.figure(figsize=figsize)\n",
    "    ax = sns.heatmap(df, annot = True, fmt=\".0%\", cmap='YlGnBu', annot_kws={'fontsize':8}, linewidths=0.5)\n",
    "    ax.set(xlabel=\"\", ylabel=\"\")\n",
    "    ax.xaxis.tick_top()\n",
    "    plt.rc('xtick', labelsize=10)\n",
    "    plt.rc('ytick', labelsize=10)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, .2, .75, 1])\n",
    "    cbar.set_ticklabels(['0%', '20%', '75%', '100%'])\n",
    "    plt.figure()\n",
    "    # sns.set(font_scale=.5)\n",
    "    # plt.show()\n",
    "    plt.close(hmap)\n",
    "    return hmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pur_by_status(df, report_fg):\n",
    "    scodes = ['BOF','BOP','FAS','FIP','FLA']\n",
    "    # fgroups = ['Accessories','Body Exterior','Body Interior','Body Structures','Chassis','Electrical','Powertrain']\n",
    "    sc = df[df['Source Code'].isin(scodes)]\n",
    "    sc_fg = sc[sc['Function Group'].isin(report_fg)]\n",
    "    sc_fg_no_co = sc_fg[sc_fg['carryover'] == False]\n",
    "    # drop duplicates from multi purchase orders\n",
    "    # sc_fg_no_co = sc_fg_no_co.drop_duplicates(subset=['Part Number_BOM','PUR/FAS'])\n",
    "    sc_fg_no_co_rel = sc_fg_no_co[sc_fg_no_co['Release Status'] == 'REL']\n",
    "    # sc_fg_no_co_rel_no_po = sc_fg_no_co_rel[~sc_fg_no_co_rel['Project'].str.contains(project_uc, na=False)]\n",
    "    sc_fg_no_co_rel_no_po = sc_fg_no_co_rel[~sc_fg_no_co_rel['Project'].str.contains(project_uc, na=False)]\n",
    "    # sc_fg_no_co_rel_no_po.groupby(['PUR/FAS']).size()\n",
    "    # sc_fg_no_co_rel_no_po['PUR/FAS'].value_counts()\n",
    "    # sc_fg_no_co_rel_no_po['Purchasing Status'].fillna('blank').value_counts(dropna=False)\n",
    "    # the final data for the charts\n",
    "    pur_by_status = sc_fg_no_co_rel_no_po['Purchasing Status'].fillna('No Reason Given')\n",
    "\n",
    "    return pur_by_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_chart(df, report_fg, figsize):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.rcParams[\"figure.figsize\"] = figsize\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "    # fgroups = ['Accessories','Body Exterior','Body Interior','Body Structures','Chassis','Electrical','Powertrain']\n",
    "\n",
    "    bars = pd.DataFrame()\n",
    "\n",
    "    for frame in ['P-BoM count','REL P-BoM count','Total Material Lines with PO Coverage']:\n",
    "        temp_df = []\n",
    "        # print (reports_dict[frame].reset_index()[reports_dict[frame].reset_index()['Source Code'] == 'Totals'])\n",
    "        temp_df = df[frame][report_fg].tail(1)\n",
    "        temp_df = temp_df.rename({'Totals':frame})\n",
    "        bars = pd.concat([bars, temp_df])\n",
    "        \n",
    "    bars = bars.transpose()\n",
    "\n",
    "    # Creating plot\n",
    "    ax = bars[['P-BoM count','REL P-BoM count','Total Material Lines with PO Coverage']].plot(kind='bar', title =\"Totals\", legend=True, fontsize=12)\n",
    "    # ax.set_xlabel(\"Hour\", fontsize=12)\n",
    "    ax.set_ylabel(\"Count of Parts\", fontsize=10)\n",
    "    ax.set_xlabel(\"\")\n",
    "    plt.rc('xtick', labelsize=10)\n",
    "\n",
    "    # Call add_value_labels. All the magic happens there.\n",
    "    add_value_labels(ax)\n",
    "    ax.set(yticklabels=[])\n",
    "    for spine in ax.spines:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    # ax = f.add_subplot(1,1,1)\n",
    "    fig = ax.get_figure()\n",
    "    plt.close(fig)\n",
    "\n",
    "    return(fig)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addActivate(wb, sheetName):\n",
    "    try:\n",
    "        sht = wb.sheets.add(sheetName)\n",
    "    except ValueError as V:\n",
    "        print (\"sheet already there: {}\".format(V))\n",
    "        sht = wb.sheets(sheetName)\n",
    "    except Exception as E:\n",
    "        print (\"sheet created\")\n",
    "        sht = wb.sheets(sheetName).activate()\n",
    "\n",
    "    return sht"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_metrics(download_dir, product):\n",
    "    \"\"\"\n",
    "    Call all data previously written to reports_dict.  Loop through and write out each to the Power bi spreadsheet\n",
    "    \"\"\"\n",
    "    import xlwings as xw\n",
    "    from openpyxl.utils.cell import get_column_letter\n",
    "\n",
    "    # if TEST:\n",
    "    #     report_metrics_filename = os.path.join(\"TEST_{}_power_bi_metrics.xlsx\".format(product))\n",
    "    # else:\n",
    "    \n",
    "    report_metrics_filename = os.path.join(download_dir / \"{}_power_bi_metrics.xlsx\".format(product))\n",
    "\n",
    "    with xw.App(visible=False) as app:\n",
    "        try:\n",
    "            wb = xw.Book(report_metrics_filename)\n",
    "            print (\"writing to existing {}\".format(report_metrics_filename))\n",
    "        except FileNotFoundError:\n",
    "            # create a new book\n",
    "            print (\"creating new {}\".format(report_metrics_filename))\n",
    "            wb = xw.Book()\n",
    "            wb.save(report_metrics_filename)\n",
    "\n",
    "        ws = addActivate(wb, 'fg_reports')\n",
    "\n",
    "        # start with a clean sheet with no contents or formatting\n",
    "        ws.clear()\n",
    "        # ws.autofit(axis=\"columns\")\n",
    "        report_time = time.strftime(time_format, time.localtime())\n",
    "\n",
    "        row_offset = 6\n",
    "\n",
    "        ws['A1'].value = 'Report Time:'\n",
    "        ws['B1'].value = report_time\n",
    "        ws['A2'].value = 'BoM last extracted:'\n",
    "        ws['B2'].value = extract_date\n",
    "\n",
    "        lightblue=(180,198,231)\n",
    "\n",
    "        # Process reports_dict\n",
    "\n",
    "        for report in fg_reports:\n",
    "            try:\n",
    "                # logit.info(\"writing: {}\".format(report))\n",
    "                # color the Header columns\n",
    "                # find the last column letter\n",
    "                last_col_letter = get_column_letter(fg_reports[report].shape[1]+2)\n",
    "                ws['B' + str(row_offset-2)].value=report\n",
    "                ws['B' + str(row_offset-2)].font.bold=True\n",
    "                ws['B' + str(row_offset-2)].font.size=16\n",
    "                ws['B' + str(row_offset)].options(pd.DataFrame, header=1, index=True).value=fg_reports[report]\n",
    "                ws.range('B{}:{}{}'.format(row_offset, last_col_letter, row_offset)).color=lightblue\n",
    "                ws.range('B{}:{}{}'.format(row_offset, last_col_letter, row_offset)).font.bold = True\n",
    "                ws['B' + str(row_offset)].options(pd.DataFrame, header=1, index=True).value=fg_reports[report]\n",
    "                # ws.range('B{}:{}{}'.format(row_offset + reports_dict[report].shape[0], last_col_letter, row_offset + reports_dict[report].shape[0])).color=lightblue\n",
    "                ws.range('B{}:{}{}'.format(row_offset + fg_reports[report].shape[0], last_col_letter, row_offset + fg_reports[report].shape[0])).font.bold = True\n",
    "                row_offset = row_offset + fg_reports[report].shape[0] + 7\n",
    "            except AttributeError:\n",
    "                # probably writing out an image rather than a dataframe\n",
    "                ws['B' + str(row_offset-2)].value=report\n",
    "                ws['B' + str(row_offset-2)].font.bold=True\n",
    "                ws['B' + str(row_offset-2)].font.size=16            \n",
    "                ws.pictures.add(fg_reports[report], name=report, update=True, left=ws.range('B' + str(row_offset)).left, top=ws.range('B' + str(row_offset)).top)\n",
    "                row_offset = row_offset + 32\n",
    "            except Exception as err:\n",
    "                # logit.exception(f\"Unexpected {err=}, {type(err)=}\")\n",
    "                print(f\"Unexpected {err=}, {type(err)=}\")\n",
    "                raise\n",
    "\n",
    "        # outrow += reports_dict[report].shape[0]+7\n",
    "        # ws.pictures.add(hmap, name=\"REL % vs P-BoM Count\", update=True, left=ws.range('M' + str(outrow)).left, top=ws.range('M' + str(outrow)).top)\n",
    "        # outrow += 17\n",
    "\n",
    "        ws = addActivate(wb, 'fg_combined')\n",
    "\n",
    "        # start with a clean sheet with no contents or formatting\n",
    "        ws.clear()\n",
    "        # ws.autofit(axis=\"columns\")\n",
    "        report_time = time.strftime(time_format, time.localtime())\n",
    "\n",
    "        row_offset = 6\n",
    "\n",
    "        ws['A1'].value = 'Report Time:'\n",
    "        ws['B1'].value = report_time\n",
    "        ws['A2'].value = 'BoM last extracted:'\n",
    "        ws['B2'].value = extract_date\n",
    "\n",
    "        lightblue=(180,198,231)\n",
    "\n",
    "        # Process reports_dict\n",
    "\n",
    "        for report in fg_combined:\n",
    "            try:\n",
    "                # logit.info(\"writing: {}\".format(report))\n",
    "                # color the Header columns\n",
    "                # find the last column letter\n",
    "                last_col_letter = get_column_letter(fg_combined[report].shape[1]+2)\n",
    "                ws['B' + str(row_offset-2)].value=report\n",
    "                ws['B' + str(row_offset-2)].font.bold=True\n",
    "                ws['B' + str(row_offset-2)].font.size=16\n",
    "                ws['B' + str(row_offset)].options(pd.DataFrame, header=1, index=True).value=fg_combined[report]\n",
    "                ws.range('B{}:{}{}'.format(row_offset, last_col_letter, row_offset)).color=lightblue\n",
    "                ws.range('B{}:{}{}'.format(row_offset, last_col_letter, row_offset)).font.bold = True\n",
    "                ws['B' + str(row_offset)].options(pd.DataFrame, header=1, index=True).value=fg_combined[report]\n",
    "                # ws.range('B{}:{}{}'.format(row_offset + reports_dict[report].shape[0], last_col_letter, row_offset + reports_dict[report].shape[0])).color=lightblue\n",
    "                ws.range('B{}:{}{}'.format(row_offset + fg_combined[report].shape[0], last_col_letter, row_offset + fg_combined[report].shape[0])).font.bold = True\n",
    "                row_offset = row_offset + fg_combined[report].shape[0] + 7\n",
    "            except AttributeError:\n",
    "                # probably writing out an image rather than a dataframe\n",
    "                ws['B' + str(row_offset-2)].value=report\n",
    "                ws['B' + str(row_offset-2)].font.bold=True\n",
    "                ws['B' + str(row_offset-2)].font.size=16            \n",
    "                ws.pictures.add(fg_combined[report], name=report, update=True, left=ws.range('B' + str(row_offset)).left, top=ws.range('B' + str(row_offset)).top)\n",
    "                row_offset = row_offset + 32\n",
    "            except Exception as err:\n",
    "                # logit.exception(f\"Unexpected {err=}, {type(err)=}\")\n",
    "                print(f\"Unexpected {err=}, {type(err)=}\")\n",
    "                raise\n",
    "\n",
    "        ws = addActivate(wb, 'BOM')\n",
    "        # start with a clean sheet with no contents or formatting\n",
    "        ws.clear()\n",
    "        # ws.autofit(axis=\"columns\")\n",
    "        report_time = time.strftime(time_format, time.localtime())\n",
    "\n",
    "        # write to sheet[0] the ordered BoM without packaging and without the 1 row of basic metrics\n",
    "        ws['A1'].options(pd.DataFrame, header=True, index=False).value=power_bi.iloc[1:, 1:]\n",
    "\n",
    "        wb.save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to existing C:\\Users\\mark_\\Downloads\\T48E-01-Z00005_power_bi_metrics.xlsx\n",
      "sheet already there: Sheet named 'fg_reports' already present in workbook\n",
      "sheet already there: Sheet named 'fg_combined' already present in workbook\n",
      "sheet already there: Sheet named 'BOM' already present in workbook\n"
     ]
    }
   ],
   "source": [
    "report_metrics(download_dir, product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "64e4acd0b8bcdde64ca4122ca150d77580571c820a6f3cf10fee72812efda0cd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
